diff --git a/CHANGELOG.md b/CHANGELOG.md
index 7f4d0f25..a37a2d0c 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,9 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
  - The x86 MCE command line option info is now updated.
 
 ### Added / support upgraded
+ - On x86:
+   - Introduce a new x2APIC driver that uses Cluster Logical addressing mode
+     for IPIs and Physical addressing mode for external interrupts.
  - Out-of-tree builds for the hypervisor now supported.
  - __ro_after_init support, for marking data as immutable after boot.
  - The project has officially adopted 4 directives and 24 rules of MISRA-C,
diff --git a/docs/misc/xen-command-line.pandoc b/docs/misc/xen-command-line.pandoc
index d9dae740..bb223129 100644
--- a/docs/misc/xen-command-line.pandoc
+++ b/docs/misc/xen-command-line.pandoc
@@ -2742,6 +2742,17 @@ the watchdog.
 
 Permit use of x2apic setup for SMP environments.
 
+### x2apic-mode (x86)
+> `= physical | cluster | mixed`
+
+> Default: `physical` if **FADT** mandates physical mode, otherwise set at
+>          build time by CONFIG_X2APIC_{PHYSICAL,LOGICAL,MIXED}.
+
+In the case that x2apic is in use, this option switches between modes to
+address APICs in the system as interrupt destinations.
+
+
+
 ### x2apic_phys (x86)
 > `= <boolean>`
 
@@ -2752,6 +2763,9 @@ In the case that x2apic is in use, this option switches between physical and
 clustered mode.  The default, given no hint from the **FADT**, is cluster
 mode.
 
+**WARNING: `x2apic_phys` is deprecated and superseded by `x2apic-mode`.
+The latter takes precedence if both are set.**
+
 ### xenheap_megabytes (arm32)
 > `= <size>`
 
diff --git a/tools/firmware/hvmloader/pci.c b/tools/firmware/hvmloader/pci.c
index 03b464da..0054be6b 100644
--- a/tools/firmware/hvmloader/pci.c
+++ b/tools/firmware/hvmloader/pci.c
@@ -118,13 +118,6 @@ void pci_setup(void)
      * Since xend can only use qemu-traditional, I think this is the
      * option that will have the least impact.
      */
-    /*
-     *  For QubesOS we default to 0. qemu-traditional is not used. 
-     *  Settings this parameter to 1 can result in memory corruption
-     *  in the guest when passingthrough big pci device like GPU.
-     */
-    bool allow_memory_relocate = 0;
-
     BUILD_BUG_ON((typeof(*pci_devfn_decode_type))PCI_COMMAND_IO !=
                  PCI_COMMAND_IO);
     BUILD_BUG_ON((typeof(*pci_devfn_decode_type))PCI_COMMAND_MEMORY !=
@@ -139,8 +132,10 @@ void pci_setup(void)
            allow_memory_relocate?"enabled":"disabled");
 
     s = xenstore_read("platform/mmio_hole_size", NULL);
-    if ( s )
+    if ( s ){
+        printf("NEOWUTRAN pci.c: modifying mmio hole size\n");
         mmio_hole_size = strtoll(s, NULL, 0);
+    }
 
     /* Program PCI-ISA bridge with appropriate link routes. */
     isa_irq = 0;
@@ -355,6 +350,13 @@ void pci_setup(void)
          *   big enough, or until it's 2GiB, or until it overlaps guest
          *   memory
          */
+        printf("NEOWUTRAN pci.c: mmio_total: %llx \n",mmio_total);
+        printf("NEOWUTRAN pci.c: pci_mem_end: %d\n",pci_mem_end);
+        printf("NEOWUTRAN pci.c: pci_mem_start: %d\n",pci_mem_start);
+        printf("NEOWUTRAN pci.c: allow_memory_relocate: %d\n",allow_memory_relocate);
+        printf("NEOWUTRAN pci.c: hvm_info->low_mem_pgend: %d\n",hvm_info->low_mem_pgend);
+
+
         while ( (mmio_total > (pci_mem_end - pci_mem_start))
                 && ((pci_mem_start << 1) != 0)
                 && (allow_memory_relocate
@@ -362,6 +364,16 @@ void pci_setup(void)
                         >= hvm_info->low_mem_pgend)) )
             pci_mem_start <<= 1;
 
+         if ( (mmio_total > (pci_mem_end - pci_mem_start))
+                && ((pci_mem_start << 1) != 0)
+                && (1
+                    || (((pci_mem_start << 1) >> PAGE_SHIFT)
+                        >= hvm_info->low_mem_pgend)) ){
+	       printf("NEOWUTRAN pci.c: HVM_LOADER would have tried to relocate guest memory\n");
+               printf("NEOWUTRAN pci.c: pci_mem_start: %d\n",pci_mem_start);
+
+	}
+
         /*
          * Try to accommodate RMRRs in our MMIO region on a best-effort basis.
          * If we have RMRRs in the range, then make pci_mem_start just after
diff --git a/tools/libs/light/libxl_dm.c b/tools/libs/light/libxl_dm.c
index fc264a3a..0535688e 100644
--- a/tools/libs/light/libxl_dm.c
+++ b/tools/libs/light/libxl_dm.c
@@ -2431,6 +2431,10 @@ void libxl__spawn_stub_dm(libxl__egc *egc, libxl__stub_dm_spawn_state *sdss)
                                        libxl__xs_get_dompath(gc, guest_domid)),
                         "%s",
                         libxl_bios_type_to_string(guest_config->b_info.u.hvm.bios));
+        libxl__xs_printf(gc, XBT_NULL,
+                         libxl__sprintf(gc, "%s/hvmloader/allow-memory-relocate", libxl__xs_get_dompath(gc, guest_domid)),
+                         "%d",
+                         0);
     }
     ret = xc_domain_set_target(ctx->xch, dm_domid, guest_domid);
     if (ret<0) {
@@ -2571,7 +2575,7 @@ static void spawn_stub_launch_dm(libxl__egc *egc,
      * Until xenconsoled learns how to handle multiple consoles, require qemu
      * in dom0 to serve consoles for a stubdomain - it require at least 3 of them.
      */
-    need_qemu = 1 || libxl__need_xenpv_qemu(gc, &sdss->dm_config);
+    need_qemu = libxl__need_xenpv_qemu(gc, &sdss->dm_config);
 
     for (i = 0; i < num_console; i++) {
         libxl__device device;
@@ -2702,16 +2706,19 @@ static void qmp_proxy_spawn_outcome(libxl__egc *egc,
                                     libxl__stub_dm_spawn_state *sdss,
                                     int rc)
 {
+    const int domid = sdss->pvqemu.guest_domid;
     STATE_AO_GC(sdss->dm.spawn.ao);
+
     /*
      * Until xenconsoled learns how to handle multiple consoles, require qemu
      * in dom0 to serve consoles for a stubdomain - it require at least 3 of them.
      */
-    int need_pvqemu = 1 || libxl__need_xenpv_qemu(gc, &sdss->dm_config);
+    int need_pvqemu = libxl__need_xenpv_qemu(gc, &sdss->dm_config);
 
     if (rc) goto out;
 
     if (need_pvqemu < 0) {
+
         rc = need_pvqemu;
         goto out;
     }
@@ -2721,12 +2728,13 @@ static void qmp_proxy_spawn_outcome(libxl__egc *egc,
     sdss->pvqemu.build_state = &sdss->dm_state;
     sdss->pvqemu.callback = spawn_stubdom_pvqemu_cb;
     if (need_pvqemu) {
+
         libxl__spawn_local_dm(egc, &sdss->pvqemu);
     } else {
+
         /* If dom0 qemu not needed, do not launch it */
         spawn_stubdom_pvqemu_cb(egc, &sdss->pvqemu, 0);
     }
-
     return;
 
 out:
@@ -2884,6 +2892,8 @@ void libxl__spawn_local_dm(libxl__egc *egc, libxl__dm_spawn_state *dmss)
     const char *dm;
     int dm_state_fd = -1;
 
+
+
     dmss_init(dmss);
 
     if (libxl_defbool_val(b_info->device_model_stubdomain)) {
@@ -2895,19 +2905,27 @@ void libxl__spawn_local_dm(libxl__egc *egc, libxl__dm_spawn_state *dmss)
         rc = ERROR_FAIL;
         goto out;
     }
+
     if (access(dm, X_OK) < 0) {
         LOGED(ERROR, domid, "device model %s is not executable", dm);
         rc = ERROR_FAIL;
         goto out;
     }
 
+
+
     rc = libxl__domain_get_device_model_uid(gc, dmss);
-    if (rc)
+    if (rc){
+
         goto out;
+    }
+
+
 
     if (b_info->device_model_version
             == LIBXL_DEVICE_MODEL_VERSION_QEMU_XEN &&
         libxl_defbool_val(b_info->dm_restrict)) {
+
         /* If we have to use dm_restrict, QEMU needs to be new enough
          * and will have the new interface where we can pre-open the
          * QMP socket. */
@@ -2918,10 +2936,14 @@ void libxl__spawn_local_dm(libxl__egc *egc, libxl__dm_spawn_state *dmss)
     rc = libxl__build_device_model_args(gc, dm, domid, guest_config,
                                           &args, &envs, state,
                                           &dm_state_fd);
-    if (rc)
+    if (rc){
+
         goto out;
 
+   }
+
     if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {
+
         path = xs_get_domain_path(ctx->xsh, domid);
         libxl__xs_printf(gc, XBT_NULL,
                          GCSPRINTF("%s/hvmloader/bios", path),
@@ -2929,6 +2951,8 @@ void libxl__spawn_local_dm(libxl__egc *egc, libxl__dm_spawn_state *dmss)
         /* Disable relocating memory to make the MMIO hole larger
          * unless we're running qemu-traditional and vNUMA is not
          * configured. */
+       LOGD(DEBUG, domid, "NEOWUTRAN spawn_local_dm: wanted value should be correctly defined");
+
         libxl__xs_printf(gc, XBT_NULL,
                          GCSPRINTF("%s/hvmloader/allow-memory-relocate", path),
                          "%d",
diff --git a/xen/arch/x86/Kconfig b/xen/arch/x86/Kconfig
index 2a5c3304..2a15a81b 100644
--- a/xen/arch/x86/Kconfig
+++ b/xen/arch/x86/Kconfig
@@ -227,11 +227,19 @@ config XEN_ALIGN_2M
 
 endchoice
 
+choice
+	prompt "x2APIC Driver default"
+	default X2APIC_MIXED
+ 	help
+	  Select APIC addressing when x2APIC is enabled.
+
+	  The default mode is mixed which should provide the best aspects
+	  of both physical and cluster modes.
+
+
 config X2APIC_PHYSICAL
-	bool "x2APIC Physical Destination mode"
+	bool "Physical Destination mode"
 	help
-	  Use x2APIC Physical Destination mode by default when available.
-
 	  When using this mode APICs are addressed using the Physical
 	  Destination mode, which allows using all dynamic vectors on each
 	  CPU independently.
@@ -241,9 +249,27 @@ config X2APIC_PHYSICAL
 	  destination inter processor interrupts (IPIs) slightly slower than
 	  Logical Destination mode.
 
-	  The mode when this option is not selected is Logical Destination.
+config X2APIC_CLUSTER
+	bool "Cluster Destination mode"
+	help
+	  When using this mode APICs are addressed using the Cluster Logical
+	  Destination mode.
+
+	  Cluster Destination has the benefit of sending IPIs faster since
+	  multiple APICs can be targeted as destinations of a single IPI.
+	  However the vector space is shared between all CPUs on the cluster,
+	  and hence using this mode reduces the number of available vectors
+	  when compared to Physical mode.
+ 
+config X2APIC_MIXED
+	bool "Mixed Destination mode"
+	help
+	  When using this mode APICs are addressed using the Cluster Logical
+	  Destination mode for IPIs and Physical mode for external interrupts.
 
-	  If unsure, say N.
+	  Should provide the best of both modes.
+
+endchoice
 
 config GUEST
 	bool
diff --git a/xen/arch/x86/genapic/x2apic.c b/xen/arch/x86/genapic/x2apic.c
index d512c50f..ab1248a4 100644
--- a/xen/arch/x86/genapic/x2apic.c
+++ b/xen/arch/x86/genapic/x2apic.c
@@ -191,6 +191,38 @@ static const struct genapic __initconstrel apic_x2apic_cluster = {
     .send_IPI_self = send_IPI_self_x2apic
 };
 
+/*
+ * Mixed x2APIC mode: use physical for external (device) interrupts, and
+ * cluster for inter processor interrupts.  Such mode has the benefits of not
+ * sharing the vector space with all CPUs on the cluster, while still allowing
+ * IPIs to be more efficiently delivered by not having to perform an ICR write
+ * for each target CPU.
+ */
+static const struct genapic __initconstrel apic_x2apic_mixed = {
+    APIC_INIT("x2apic_mixed", NULL),
+
+    /*
+     * The following fields are exclusively used by external interrupts and
+     * hence are set to use Physical destination mode handlers.
+     */
+    .int_delivery_mode = dest_Fixed,
+    .int_dest_mode = 0 /* physical delivery */,
+    .vector_allocation_cpumask = vector_allocation_cpumask_phys,
+    .cpu_mask_to_apicid = cpu_mask_to_apicid_phys,
+
+    /*
+     * The following fields are exclusively used by IPIs and hence are set to
+     * use Cluster Logical destination mode handlers.  Note that init_apic_ldr
+     * is not used by IPIs, but the per-CPU fields it initializes are only used
+     * by the IPI hooks.
+     */
+    .init_apic_ldr = init_apic_ldr_x2apic_cluster,
+    .send_IPI_mask = send_IPI_mask_x2apic_cluster,
+    .send_IPI_self = send_IPI_self_x2apic,
+};
+
+
+
 static int cf_check update_clusterinfo(
     struct notifier_block *nfb, unsigned long action, void *hcpu)
 {
@@ -231,38 +263,62 @@ static struct notifier_block x2apic_cpu_nfb = {
 static int8_t __initdata x2apic_phys = -1;
 boolean_param("x2apic_phys", x2apic_phys);
 
+enum {
+   unset, physical, cluster, mixed
+} static __initdata x2apic_mode = unset;
+
+static int __init cf_check parse_x2apic_mode(const char *s)
+{
+    if ( !cmdline_strcmp(s, "physical") )
+        x2apic_mode = physical;
+    else if ( !cmdline_strcmp(s, "cluster") )
+        x2apic_mode = cluster;
+    else if ( !cmdline_strcmp(s, "mixed") )
+        x2apic_mode = mixed;
+    else
+        return -EINVAL;
+
+    return 0;
+}
+custom_param("x2apic-mode", parse_x2apic_mode);
+
+
+
 const struct genapic *__init apic_x2apic_probe(void)
 {
-    if ( x2apic_phys < 0 )
-    {
-        /*
-         * Force physical mode if there's no (full) interrupt remapping support:
-         * The ID in clustered mode requires a 32 bit destination field due to
-         * the usage of the high 16 bits to hold the cluster ID.
-         */
-        x2apic_phys = iommu_intremap != iommu_intremap_full ||
-                      (acpi_gbl_FADT.flags & ACPI_FADT_APIC_PHYSICAL) ||
-                      (IS_ENABLED(CONFIG_X2APIC_PHYSICAL) &&
-                       !(acpi_gbl_FADT.flags & ACPI_FADT_APIC_CLUSTER));
+    /* Honour the legacy cmdline setting if it's the only one provided. */
+    if ( x2apic_mode == unset && x2apic_phys >= 0 ){
+        x2apic_mode = x2apic_phys ? physical : cluster;
     }
-    else if ( !x2apic_phys )
-        switch ( iommu_intremap )
+
+    if ( x2apic_mode == unset )
+    {
+        if ( acpi_gbl_FADT.flags & ACPI_FADT_APIC_PHYSICAL )
         {
-        case iommu_intremap_off:
-        case iommu_intremap_restricted:
-            printk("WARNING: x2APIC cluster mode is not supported %s interrupt remapping -"
-                   " forcing phys mode\n",
-                   iommu_intremap == iommu_intremap_off ? "without"
-                                                        : "with restricted");
-            x2apic_phys = true;
-            break;
 
-        case iommu_intremap_full:
-            break;
+            printk(XENLOG_INFO "ACPI FADT forcing x2APIC physical mode\n");
+            x2apic_mode = physical;
+         }
+        else{
+            x2apic_mode = IS_ENABLED(CONFIG_X2APIC_MIXED) ? mixed
+                          : (IS_ENABLED(CONFIG_X2APIC_PHYSICAL) ? physical
+                                                                : cluster);
         }
+    }
 
-    if ( x2apic_phys )
+
+    if ( x2apic_mode == physical ){
         return &apic_x2apic_phys;
+    }
+
+    if ( x2apic_mode == cluster && iommu_intremap != iommu_intremap_full )
+    {
+        printk("WARNING: x2APIC cluster mode is not supported %s interrupt remapping -"
+               " forcing mixed mode\n",
+               iommu_intremap == iommu_intremap_off ? "without"
+                                                    : "with restricted");
+        x2apic_mode = mixed;
+    }
 
     if ( !this_cpu(cluster_cpus) )
     {
@@ -272,7 +328,8 @@ const struct genapic *__init apic_x2apic_probe(void)
         register_cpu_notifier(&x2apic_cpu_nfb);
     }
 
-    return &apic_x2apic_cluster;
+    return x2apic_mode == cluster ? &apic_x2apic_cluster : &apic_x2apic_mixed;
+
 }
 
 void __init check_x2apic_preenabled(void)
